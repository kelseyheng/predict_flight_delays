{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score, confusion_matrix, make_scorer, accuracy_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dec_flights_model_copy.pickle','rb') as read_file:\n",
    "    dec_flights = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_time', 'num_flights', 'distance', 'delay_level',\n",
       "       'scheduled_arr_hr', 'airline_AA', 'airline_AS', 'airline_B6',\n",
       "       'airline_DL', 'airline_EV',\n",
       "       ...\n",
       "       'dest_SFO', 'dest_SHD', 'dest_SLC', 'dest_SLN', 'dest_SPN', 'dest_STS',\n",
       "       'dest_SWO', 'dest_TPA', 'dest_UIN', 'dest_VEL'],\n",
       "      dtype='object', length=152)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_flights.drop(columns=['carrier_delay','weather_delay','nas_delay','security_delay','late_aircraft_delay', 'dep_delay_indict','arr_delayed_indict'],axis=1,inplace=True)\n",
    "dec_flights.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test_spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-afd0dc7d11e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# hold out 20% of the data for final testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         y = check_array(y, accept_sparse=['csr', 'csc'], dtype=None,\n\u001b[1;32m    103\u001b[0m                         ensure_2d=False)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "X1, y1 = dec_flights.drop('delay_level',axis=1), dec_flights['delay_level']\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X, y = RandomUnderSampler(random_state=42).fit_sample(X1,y1)\n",
    "\n",
    "# hold out 20% of the data for final testing\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)\n",
    "\n",
    "#further spilt into 60% and 20% for train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise model\n",
    "model = ['Logistic']\n",
    "accuracy = []\n",
    "f1 = []\n",
    "auc = []\n",
    "recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuned\n",
    "model_2 = ['Logistic']\n",
    "accuracy_2 = []\n",
    "f1_2 = []\n",
    "auc_2 = []\n",
    "recall_2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, y_train)\n",
    "print(\"The score for logistic regression is\")\n",
    "print(\"Training: {:6.2f}%\".format(100*logistic.score(X_train, y_train)))\n",
    "print(\"Validate: {:6.2f}%\".format(100*logistic.score(X_val, y_val)))\n",
    "print(\"Test set: {:6.2f}%\".format(100*logistic.score(X_test, y_test)))\n",
    "print(\"Log-loss: {:6.4f}\".format(log_loss(y_test, logistic.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_pred = logistic.predict(X_val)\n",
    "print('Logistic Results:')\n",
    "print(confusion_matrix(y_val,logistic_pred))\n",
    "print(classification_report(y_val, logistic_pred))\n",
    "logistic_score = logistic.fit(X_train, y_train).score(X_val, y_val)\n",
    "print('Logistic score: %f' % logistic_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pred = logistic.predict(X_test)\n",
    "logistic_f1 = f1_score(logistic_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_y_score = logistic.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#calculate roc curve\n",
    "logistic_fpr, logistic_tpr, logistic_auc_thresholds = roc_curve(y_val, logistic_y_score)\n",
    "\n",
    "#calculate auc\n",
    "auc_logistic = roc_auc_score(y_val, logistic_y_score)\n",
    "print('AUC: %.3f' % auc_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_logistic = recall_score(y_train, logistic.predict(X_train))\n",
    "print('Recall: %.3f' % recall_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.append(logistic_score)\n",
    "print('Accuracy: ',accuracy)\n",
    "\n",
    "f1.append(logistic_f1)\n",
    "print('F1: ', f1)\n",
    "\n",
    "auc.append(auc_logistic)\n",
    "print('AUC: ', auc)\n",
    "\n",
    "recall.append(recall_logistic)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomised Search Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LogisticRegression()\n",
    "\n",
    "rf_p_dist={\n",
    "           'C':[0.1,0.5,1,5,10],\n",
    "           'fit_intercept':[True,False],\n",
    "           'verbose':[0.1,0.5,1.0,3,5],\n",
    "           'max_iter':[1,5,10,20,50]\n",
    "          }\n",
    "\n",
    "def hypertuning_rscv(est, p_distr, nbr_iter,X,y):\n",
    "    rdmsearch = RandomizedSearchCV(est, param_distributions=p_distr,\n",
    "                                  n_jobs=-1, n_iter=nbr_iter, cv=5)\n",
    "    #CV = Cross-Validation ( here using Stratified KFold CV)\n",
    "    rdmsearch.fit(X,y)\n",
    "    ht_params = rdmsearch.best_params_\n",
    "    ht_score = rdmsearch.best_score_\n",
    "    return ht_params, ht_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertuning_rscv(est, rf_p_dist, 40, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic2 = LogisticRegression(C=10, verbose=5, max_iter=50, fit_intercept=True)\n",
    "logistic2.fit(X_train, y_train)\n",
    "print(\"The score for logistic regression is\")\n",
    "print(\"Training: {:6.2f}%\".format(100*logistic2.score(X_train, y_train)))\n",
    "print(\"Validate: {:6.2f}%\".format(100*logistic2.score(X_val, y_val)))\n",
    "print(\"Test set: {:6.2f}%\".format(100*logistic2.score(X_test, y_test)))\n",
    "print(\"Log-loss: {:6.4f}\".format(log_loss(y_test, logistic2.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic2_pred = logistic2.predict(X_val)\n",
    "print('Logistic Results:')\n",
    "print(confusion_matrix(y_val,logistic2_pred))\n",
    "print(classification_report(y_val, logistic2_pred))\n",
    "logistic2_score = logistic2.fit(X_train, y_train).score(X_val, y_val)\n",
    "print('Logistic score: %f' % logistic2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic2_pred = logistic2.predict(X_test)\n",
    "f1_score(logistic2_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic2_y_score = logistic2.predict_proba(X_val)[:, 1]\n",
    "#calculate roc curve\n",
    "logistic_fpr, logistic_tpr, logistic_auc_thresholds = roc_curve(y_val, logistic2_y_score)\n",
    "\n",
    "#calculate auc\n",
    "auc_logistic2 = roc_auc_score(y_val, logistic2_y_score)\n",
    "print('AUC: %.3f' % auc_logistic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_logistic2 = recall_score(y_train, logistic2.predict(X_train))\n",
    "print('Recall: %.3f' % recall_logistic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_2.append(logistic2_score)\n",
    "print('Accuracy: ',accuracy_2)\n",
    "\n",
    "logistic2_f1 = f1_score(logistic2_pred, y_test)\n",
    "f1_2.append(logistic2_f1)\n",
    "print('F1: ', f1_2)\n",
    "\n",
    "auc_2.append(auc_logistic2)\n",
    "print('AUC: ', auc_2)\n",
    "\n",
    "recall_2.append(recall_logistic2)\n",
    "print('Recall: ', recall_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise model\n",
    "model = ['Logistic', 'Bernoulli', 'Forest']\n",
    "accuracy = []\n",
    "f1 = []\n",
    "auc = []\n",
    "recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [0.9132170538698307, 0.9132170538698307, 0.8978068081388852]\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.despine()\n",
    "ax = sns.barplot(x=model, y=accuracy,color='#85cbb3')\n",
    "\n",
    "# plt.title('Accuracy Score', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Model', fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=14)\n",
    "\n",
    "#plt.ylabel('Score', fontsize=14, fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim([0,1.0])\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "plt.savefig('accuracy_score_refined.jpg', transparent=True)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.despine()\n",
    "ax = sns.barplot(x=model, y=f1,color='#85cbb3')\n",
    "\n",
    "# plt.title('F1 Score', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Model', fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=14)\n",
    "\n",
    "#plt.ylabel('Score', fontsize=14, fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim([0,1.0])\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "# plt.savefig('f1_score_refined.jpg', transparent=True)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.despine()\n",
    "ax = sns.barplot(x=model, y=auc,color='#85cbb3')\n",
    "\n",
    "plt.title('Area Under Curve(AUC)', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Model', fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=14)\n",
    "\n",
    "#plt.ylabel('Score', fontsize=14, fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim([0,1.0])\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.despine()\n",
    "ax = sns.barplot(x=model, y=recall,color='#85cbb3')\n",
    "\n",
    "# plt.title('Recall Score', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Model', fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=14)\n",
    "\n",
    "#plt.ylabel('Score', fontsize=14, fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim([0,1.0])\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "\n",
    "plt.savefig('recall_refined.jpg', transparent=True)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
